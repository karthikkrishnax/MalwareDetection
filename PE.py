import os
import pandas as pd
import numpy as np
import pickle
import pefile
import sklearn.ensemble as ek
from sklearn.feature_selection import SelectFromModel
import joblib
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (confusion_matrix, roc_curve, auc, precision_score, recall_score, f1_score, accuracy_score)
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV
from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier)
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import roc_auc_score
from imblearn.over_sampling import SMOTE

dataset = pd.read_csv('C:/Users/karth/Downloads/Malware-Detection-using-Machine-learning-main (1)/ML/Dataset/data.csv', sep='|')

X = dataset.drop(['Name', 'md5', 'legitimate'], axis=1).values
y = dataset['legitimate'].values

legitimate_count = dataset['legitimate'].value_counts()
print(legitimate_count)

extratrees = ek.ExtraTreesClassifier().fit(X, y)
model = SelectFromModel(extratrees, prefit=True)
X_new = model.transform(X)
nbfeatures = X_new.shape[1]

print(f"Number of important features: {nbfeatures}")

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.29, stratify=y)

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

print("\nClass distribution after SMOTE:")
class_proportions_after = np.bincount(y_train_resampled)
print(f"Legitimate (0): {class_proportions_after[0]}")
print(f"Malware (1): {class_proportions_after[1]}")

models = {
    "DecisionTree": DecisionTreeClassifier(max_depth=10),
    "RandomForest": RandomForestClassifier(),
    "LogisticRegression": LogisticRegression(solver='liblinear', max_iter=1000),
    "KNN": KNeighborsClassifier(),
    "NaiveBayes": GaussianNB(),
    "GradientBoosting": GradientBoostingClassifier(),
}

param_distributions = {
    "DecisionTree": {
        "max_depth": np.arange(3, 30, 3),
        "min_samples_split": np.arange(2, 10, 1),
        "min_samples_leaf": np.arange(1, 5, 1),
        "criterion": ["gini", "entropy"],
    },
    "RandomForest": {
        "n_estimators": np.arange(10, 200, 10),
        "max_depth": np.arange(5, 30, 5),
        "min_samples_split": np.arange(2, 10, 1),
        "min_samples_leaf": np.arange(1, 5, 1),
        "criterion": ["gini", "entropy"],
    },
    "LogisticRegression": {
        "penalty": ['l1', 'l2'],
        "C": np.logspace(-3, 3, 7),
        "solver": ['liblinear', 'saga'],
    },
    "KNN": {
        "n_neighbors": np.arange(1, 30, 1),
        "weights": ['uniform', 'distance'],
        "metric": ['euclidean', 'manhattan', 'minkowski']
    },
    "NaiveBayes": {
        "var_smoothing": np.logspace(-9, 0, 100),
    },
    "GradientBoosting": {
        "n_estimators": [50, 100, 150],
        "learning_rate": [0.01, 0.1, 0.2],
        "max_depth": np.arange(3, 10, 1),
        "subsample": [0.8, 0.9, 1.0],
    },
}

results = {}
accuracy = []
precision = []
recall = []
f1_scores = []

kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for name, model in models.items():
    print(f"Training {name}...")
    
    if name in param_distributions:
        search = RandomizedSearchCV(model, param_distributions[name], n_iter=10, scoring='accuracy', cv=kf, random_state=42)
        search.fit(X_train_resampled, y_train_resampled)
        best_model = search.best_estimator_
    else:
        best_model = model.fit(X_train_resampled, y_train_resampled)
    
    y_pred = best_model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results[name] = acc
    accuracy.append(acc)
    precision.append(prec)
    recall.append(rec)
    f1_scores.append(f1)

    print(f"{name}: Accuracy = {acc:.2f}, Precision = {prec:.2f}, Recall = {rec:.2f}, F1-score = {f1:.2f}")

best_model_name = max(results, key=results.get)
print(f"\nBest model: {best_model_name} with Accuracy: {results[best_model_name]:.2f}")

metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
metrics_values = [accuracy, precision, recall, f1_scores]

fig, ax = plt.subplots(figsize=(10, 6))
bar_width = 0.2
index = np.arange(len(models))

for i, metric in enumerate(metrics_values):
    plt.bar(index + i * bar_width, metric, bar_width, label=metrics_names[i])

plt.xlabel('Model')
plt.ylabel('Scores')
plt.title('Model Comparison')
plt.xticks(index + bar_width, list(models.keys()), rotation=45)
plt.legend()
plt.tight_layout()
plt.show()

y_pred_best = best_model.predict(X_test)
y_pred_proba = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, 'predict_proba') else best_model.decision_function(X_test)

conf_matrix = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Legitimate', 'Malware'], yticklabels=['Legitimate', 'Malware'])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title(f'Confusion Matrix for {best_model_name}')
plt.show()

fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title(f'Receiver Operating Characteristic for {best_model_name}')
plt.legend(loc="lower right")
plt.show()
