import pandas as pd
import numpy as np
import random
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, RandomizedSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score
from imblearn.over_sampling import RandomOverSampler
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

url = 'C:/Users/karth/Downloads/Malware-Detection-using-Machine-learning-main (1)/ML/Dataset/data_url.csv'
url_csv = pd.read_csv(url, on_bad_lines='skip')
url_df = pd.DataFrame(url_csv)
print("Class distribution:\n", url_df['label'].value_counts())

urls = url_df['url'].values
y = url_df['label'].values

def sanitization(web):
    web = web.lower()
    token = []
    dot_token_slash = []
    raw_slash = str(web).split('/')
    for i in raw_slash:
        raw1 = str(i).split('-')
        slash_token = []
        for j in range(len(raw1)):
            raw2 = str(raw1[j]).split('.')
            slash_token += raw2
        dot_token_slash += raw1 + slash_token
    token = list(set(dot_token_slash))  
    if 'com' in token:
        token.remove('com')
    return token

vectorizer = TfidfVectorizer(tokenizer=sanitization)
x = vectorizer.fit_transform(urls)

split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)

for train_index, test_index in split.split(urls, y):
    x_train, x_test = x[train_index], x[test_index]
    y_train, y_test = y[train_index], y[test_index]

ros = RandomOverSampler(random_state=42)
x_train_res, y_train_res = ros.fit_resample(x_train, y_train)

label_encoder = LabelEncoder()
y_train_res = label_encoder.fit_transform(y_train_res)
y_test_encoded = label_encoder.transform(y_test)

models = {
    "Logistic Regression": (LogisticRegression(max_iter=100), {
        'C': [0.1, 1.0, 10.0],
        'penalty': ['l2'],
        'solver': ['liblinear']
    }),
    "K-Nearest Neighbors": (KNeighborsClassifier(), {
        'n_neighbors': [3, 5],
        'weights': ['uniform'],
    }),
    "Decision Tree": (DecisionTreeClassifier(), {
        'max_depth': [5, 10],
        'min_samples_split': [2, 5],
    }),
    "Random Forest": (RandomForestClassifier(), {
        'n_estimators': [50, 100],
        'max_depth': [5, 10],
    }),
    "Gradient Boosting": (GradientBoostingClassifier(), {
        'n_estimators': [50],
        'learning_rate': [0.1],
        'max_depth': [3],
    }),
}

cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)

results = {}
for name, (model, params) in models.items():
    print(f"\nTuning {name}...")
    grid_search = RandomizedSearchCV(model, params, n_iter=5, cv=cv, scoring='accuracy', n_jobs=-1, random_state=42)
    grid_search.fit(x_train_res, y_train_res)

    best_model = grid_search.best_estimator_
    best_score = grid_search.best_score_

    y_pred = best_model.predict(x_test)
    y_pred_encoded = label_encoder.transform(y_pred)
    test_accuracy = accuracy_score(y_test_encoded, y_pred_encoded)

    roc_auc_value = roc_auc_score(y_test_encoded, best_model.predict_proba(x_test)[:, 1])

    results[name] = {
        'Best Score': best_score,
        'Test Accuracy': test_accuracy,
        'Best Parameters': grid_search.best_params_,
        'ROC AUC': roc_auc_value
    }
    print(f"{name} Best CV Score: {100 * best_score:.2f}%, Test Accuracy: {100 * test_accuracy:.2f}%")

best_model_name = max(results, key=lambda k: results[k]['Test Accuracy'])
best_model_score = results[best_model_name]['Test Accuracy']
print(f"\nBest model: {best_model_name} with Test Accuracy: {100 * best_model_score:.2f}%")
print("Best Parameters:", results[best_model_name]['Best Parameters'])

fpr, tpr, _ = roc_curve(y_test_encoded, best_model.predict_proba(x_test)[:, 1])
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, color='blue', label=f"ROC Curve (AUC = {results[best_model_name]['ROC AUC']:.2f})")
plt.plot([0, 1], [0, 1], color='red', linestyle='--')
plt.title(f'ROC Curve for {best_model_name}')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(loc='lower right')
plt.show()

conf_matrix = confusion_matrix(y_test_encoded, y_pred_encoded)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
plt.title(f'Confusion Matrix for {best_model_name}')
plt.show()

precision = precision_score(y_test_encoded, y_pred_encoded)
recall = recall_score(y_test_encoded, y_pred_encoded)
f1 = f1_score(y_test_encoded, y_pred_encoded)

print(f"\nPrecision: {precision:.2f}")
print(f"Recall: {recall:.2f}")
print(f"F1 Score: {f1:.2f}")

results[best_model_name].update({
    'Confusion Matrix': conf_matrix,
    'Precision': precision,
    'Recall': recall,
    'F1 Score': f1
})

print(f"\nBest model: {best_model_name} with Test Accuracy: {100 * best_model_score:.2f}%")
print(f"ROC AUC Score: {results[best_model_name]['ROC AUC']:.2f}")
print("Best Parameters:", results[best_model_name]['Best Parameters'])
